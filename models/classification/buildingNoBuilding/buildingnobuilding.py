# -*- coding: utf-8 -*-
"""BuildingNoBuilding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AdpYF7HiVO-eYV3FZMg1HClRnfwqBQsF

#Data Preparation
"""

#Installing required libraries of tf  and keras
# !pip install Keras==2.2.4
# !pip install tensorflow==1.13.1

# !pip install tensorflow==1.15.2
# !pip install tensorflow-gpu

from os.path import join
import os
import sys
import shutil
#Downsample the images so they are smaller.
from skimage.transform import downscale_local_mean

#to read the images 
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
from PIL import Image

#to build the model
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
from keras import backend as K
K.set_image_dim_ordering('th')
import numpy as np
import cv2
import tensorflow as tf

#ignore warnings
import warnings
warnings.filterwarnings('ignore')

"""### Defnes some helpful functions"""


os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

if tf.test.gpu_device_name():
    print('GPU found')
else:
    print("No GPU found")


def get_pred(img_path):
  X = np.array(Image.open(img_path).convert('L'))
  X = cv2.resize(X,( 256,256),cv2.INTER_AREA)
  X_array = [X,]
  downscaled_X = [downscale_local_mean(X, (4,4)) for X in X_array]
  # downscaled_X[0].shape
  shape = list(downscaled_X[0].shape)
  shape[:0] = [len(downscaled_X)]
  X_reshaped = np.concatenate(downscaled_X).reshape(shape)

  X1 = X_reshaped.reshape(X_reshaped.shape[0], 1, X_reshaped[0].shape[0], X_reshaped[0].shape[1]).astype('float32')
  X1 = X1 / 255

  y_pred = model_inference.predict_classes(X1, batch_size=10)


  prediction = ['no_building', 'building'][1-y_pred[0]]

  return prediction



def create_dir(dir_path):
	if not os.path.exists(dir_path):
		os.makedirs(dir_path)
	print("Done")

building_dir = 'results/building'
no_building_dir = 'results/no_building'

create_dir(building_dir)
create_dir(no_building_dir)

model_name = "building_no_buildingCocodyBingerville" #Nom du modele après sauvegarde
model_inference =  tf.keras.models.load_model(join("models", model_name + ".h5")) #chemin du modèle exporté
# model_inference.summary()

if __name__ == "__main__":
    arg = sys.argv[:]
    if len(arg) < 3:
        print('Not enough arguments!\n')
        print('python buildingnobuilding.py path_to_images  ext')
        exit(0)

    dir_path = str(arg[1])
    ext  = str(arg[2])


    for dirpath, dirnames, filenames in os.walk(dir_path):
        for filename in filenames:
          if filename.endswith(ext):
            # print(filename)
             full_path = os.path.join(dirpath, filename)

             prediction = get_pred(full_path)
             if prediction=='building':
               dst_path = os.path.join(building_dir, filename)
               shutil.move(full_path,dst_path)
             elif prediction=='no_building':
               dst_path = os.path.join(no_building_dir, filename)
               shutil.move(full_path,dst_path)


    building_tiles = 0
    no_building_tiles = 0
    for dirname in os.listdir(dst_path):
      dir_full = os.path.join(dst_path,dirname)
      for subdir in os.listdir(dir_full):
        if subdir=='building':
          building_tiles +=len(os.listdir(subdir_full))
        elif subdir=='no_building':
          no_building_tiles +=len(os.listdir(subdir_full))
        subdir_full = os.path.join(dir_full, subdir)
        print(f'{dirname}, {subdir}, {len(os.listdir(subdir_full))}')

    print('building counts: ', building_tiles)
    print('no building counts: ', no_building_tiles)
#python  buildingnobuilding.py /images /results .tif